{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c4e5feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:41:52) [Clang 15.0.7 ]\n"
     ]
    }
   ],
   "source": [
    "# Test to see why imports are not working as expected\n",
    "import sys \n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "292f6089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- -----------\r\n",
      "absl-py                       1.2.0\r\n",
      "anyio                         3.6.1\r\n",
      "appnope                       0.1.3\r\n",
      "argon2-cffi                   21.3.0\r\n",
      "argon2-cffi-bindings          21.2.0\r\n",
      "asttokens                     2.0.8\r\n",
      "astunparse                    1.6.3\r\n",
      "attrs                         22.1.0\r\n",
      "Babel                         2.10.3\r\n",
      "backcall                      0.2.0\r\n",
      "backports.functools-lru-cache 1.6.4\r\n",
      "beautifulsoup4                4.12.2\r\n",
      "bleach                        5.0.1\r\n",
      "brotlipy                      0.7.0\r\n",
      "cached-property               1.5.2\r\n",
      "cachetools                    5.2.0\r\n",
      "certifi                       2022.9.24\r\n",
      "cffi                          1.15.1\r\n",
      "charset-normalizer            2.1.1\r\n",
      "colorama                      0.4.5\r\n",
      "conda                         22.9.0\r\n",
      "conda-package-handling        1.8.1\r\n",
      "contourpy                     1.0.7\r\n",
      "cryptography                  37.0.4\r\n",
      "cycler                        0.11.0\r\n",
      "debugpy                       1.6.3\r\n",
      "decorator                     5.1.1\r\n",
      "defusedxml                    0.7.1\r\n",
      "entrypoints                   0.4\r\n",
      "executing                     1.1.0\r\n",
      "fastjsonschema                2.16.2\r\n",
      "flatbuffers                   22.9.24\r\n",
      "flit_core                     3.7.1\r\n",
      "fonttools                     4.39.4\r\n",
      "gast                          0.4.0\r\n",
      "google-auth                   2.12.0\r\n",
      "google-auth-oauthlib          0.4.6\r\n",
      "google-pasta                  0.2.0\r\n",
      "grpcio                        1.46.3\r\n",
      "h5py                          3.6.0\r\n",
      "idna                          3.3\r\n",
      "importlib-metadata            4.11.4\r\n",
      "importlib-resources           5.9.0\r\n",
      "ipykernel                     6.16.0\r\n",
      "ipython                       8.5.0\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    8.0.2\r\n",
      "jedi                          0.18.1\r\n",
      "Jinja2                        3.1.2\r\n",
      "json5                         0.9.10\r\n",
      "jsonschema                    4.16.0\r\n",
      "jupyter                       1.0.0\r\n",
      "jupyter_client                7.3.5\r\n",
      "jupyter-console               6.4.4\r\n",
      "jupyter_core                  4.11.1\r\n",
      "jupyter-server                1.19.1\r\n",
      "jupyterlab                    3.4.7\r\n",
      "jupyterlab-pygments           0.2.2\r\n",
      "jupyterlab_server             2.15.2\r\n",
      "jupyterlab-widgets            3.0.3\r\n",
      "keras                         2.10.0\r\n",
      "Keras-Preprocessing           1.1.2\r\n",
      "kiwisolver                    1.4.4\r\n",
      "libclang                      14.0.6\r\n",
      "Markdown                      3.4.1\r\n",
      "MarkupSafe                    2.1.1\r\n",
      "matplotlib                    3.7.1\r\n",
      "matplotlib-inline             0.1.6\r\n",
      "mistune                       0.8.4\r\n",
      "nbclassic                     0.4.3\r\n",
      "nbclient                      0.5.13\r\n",
      "nbconvert                     6.4.5\r\n",
      "nbformat                      5.6.1\r\n",
      "nest-asyncio                  1.5.5\r\n",
      "notebook                      6.4.12\r\n",
      "notebook-shim                 0.1.0\r\n",
      "numpy                         1.23.2\r\n",
      "oauthlib                      3.2.1\r\n",
      "opt-einsum                    3.3.0\r\n",
      "packaging                     21.3\r\n",
      "pandas                        2.0.2\r\n",
      "pandocfilters                 1.5.0\r\n",
      "parso                         0.8.3\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        9.5.0\r\n",
      "pip                           22.2.2\r\n",
      "pkgutil_resolve_name          1.3.10\r\n",
      "prometheus-client             0.14.1\r\n",
      "prompt-toolkit                3.0.31\r\n",
      "protobuf                      3.19.4\r\n",
      "psutil                        5.9.2\r\n",
      "ptyprocess                    0.7.0\r\n",
      "pure-eval                     0.2.2\r\n",
      "pyasn1                        0.4.8\r\n",
      "pyasn1-modules                0.2.8\r\n",
      "pycosat                       0.6.3\r\n",
      "pycparser                     2.21\r\n",
      "Pygments                      2.13.0\r\n",
      "pyOpenSSL                     22.0.0\r\n",
      "pyparsing                     3.0.9\r\n",
      "pyrsistent                    0.18.1\r\n",
      "PySocks                       1.7.1\r\n",
      "python-dateutil               2.8.2\r\n",
      "pytz                          2022.2.1\r\n",
      "pyzmq                         24.0.1\r\n",
      "qtconsole                     5.4.3\r\n",
      "QtPy                          2.3.1\r\n",
      "requests                      2.31.0\r\n",
      "requests-oauthlib             1.3.1\r\n",
      "rsa                           4.9\r\n",
      "ruamel-yaml-conda             0.15.80\r\n",
      "scipy                         1.10.1\r\n",
      "Send2Trash                    1.8.0\r\n",
      "setuptools                    65.2.0\r\n",
      "six                           1.16.0\r\n",
      "sniffio                       1.3.0\r\n",
      "soupsieve                     2.3.2.post1\r\n",
      "stack-data                    0.5.1\r\n",
      "tensorboard                   2.10.1\r\n",
      "tensorboard-data-server       0.6.1\r\n",
      "tensorboard-plugin-wit        1.8.1\r\n",
      "tensorflow-estimator          2.10.0\r\n",
      "tensorflow-metal              0.6.0\r\n",
      "termcolor                     2.0.1\r\n",
      "terminado                     0.15.0\r\n",
      "testpath                      0.6.0\r\n",
      "tomli                         2.0.1\r\n",
      "toolz                         0.12.0\r\n",
      "tornado                       6.2\r\n",
      "tqdm                          4.64.0\r\n",
      "traitlets                     5.4.0\r\n",
      "typing_extensions             4.3.0\r\n",
      "tzdata                        2023.3\r\n",
      "urllib3                       1.26.11\r\n",
      "wcwidth                       0.2.5\r\n",
      "webencodings                  0.5.1\r\n",
      "websocket-client              1.4.1\r\n",
      "Werkzeug                      2.2.2\r\n",
      "wheel                         0.37.1\r\n",
      "widgetsnbextension            4.0.3\r\n",
      "wrapt                         1.14.1\r\n",
      "zipp                          3.8.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41cfa18",
   "metadata": {},
   "source": [
    "Power of Semantics Search combined with Elastic Search | ML on ELK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede982fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import json\n",
    "    import os\n",
    "    import uuid\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    import elasticsearch\n",
    "    \n",
    "    from elasticsearch import Elasticsearch\n",
    "    from elasticsearch import helpers\n",
    "    from sentence_transformers import SentenceTransformer, util\n",
    "    from tqdm import tqdm\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv(\"secret.env\")\n",
    "except Exception as e:\n",
    "    print(\"Some Modules are Missing :{}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97b467a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create the client instance\\nclient = Elasticsearch(\\n    cloud_id=CLOUD_ID,\\n    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\\n)\\n\\n# Successful response!\\nclient.info()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Password for the 'elastic' user generated by Elasticsearch\n",
    "ELASTIC_PASSWORD = \"900x3MM9iJ6aLSxkpeqfRpLe\"\n",
    "\n",
    "# Found in the 'Manage Deployment' page\n",
    "CLOUD_ID = \"My_deployment:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvOjQ0MyRiMmYwN2IyNmUyYTE0MzlkYThhNjQ0ZmVhNDZmYzAzNSQ5ZTAxZDAyMzY0Mjk0MGU1YWQ1MzJlMThhNDAyMzljMA==\"\n",
    "'''\n",
    "# Create the client instance\n",
    "client = Elasticsearch(\n",
    "    cloud_id=CLOUD_ID,\n",
    "    basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
    ")\n",
    "\n",
    "# Successful response!\n",
    "client.info()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ab4643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reader(object):\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        df = pd.read_csv(self.file_name, chunksize=3000)\n",
    "        df = next(df)\n",
    "        df = df.fillna(\"\")\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b238c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def get_token(self, documents):\n",
    "        sentences  = [documents]\n",
    "        sentence_embeddings = self.model.encode(sentences, convert_to_tensor=True)\n",
    "        #encod_list = sentence_embeddings.numpy()\n",
    "        _ = list(sentence_embeddings.flatten())\n",
    "        encod_np_array = np.array(_)\n",
    "        encod_list = encod_np_array.tolist()\n",
    "        return encod_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e5d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticSearchImports(object):\n",
    "    def __init__(self, df, index_name='posting'):\n",
    "        self.df = df\n",
    "        self.index_name = index_name\n",
    "        self.es = Elasticsearch(\"https://localhost:9200\", basic_auth=('elastic', 'OKzimtr0od5trZ0j=DUm'))\n",
    "        \n",
    "        '''\n",
    "        self.es = client = Elasticsearch(\n",
    "            cloud_id=CLOUD_ID,\n",
    "            basic_auth=(\"elastic\", ELASTIC_PASSWORD)\n",
    "        )\n",
    "        '''\n",
    "\n",
    "        #self.es = Elasticsearch(timeout=600,hosts=os.getenv(\"ENDPOINT\"), basic_auth=('username', 'password'))\n",
    "        #self.es = Elasticsearch(timeout=600,hosts=os.getenv(\"ENDPOINT\"))\n",
    "        #es = Elasticsearch( \"https://localhost:9200\",ca_certs=\"/path/to/http_ca.crt\", basic_auth=(\"elastic\", ELASTIC_PASSWORD))\n",
    "\n",
    "    def run(self):\n",
    "\n",
    "        elk_data = self.df.to_dict(\"records\")\n",
    "\n",
    "        for job in elk_data:\n",
    "            try:self.es.index(index=self.index_name,body=job)\n",
    "            except Exception as e:pass\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f48a09",
   "metadata": {},
   "source": [
    "# Converting column to Vector Enbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13e4967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = Reader(file_name=\"data job posts.csv\")\n",
    "df = helper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263b1af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       AMERIA Investment Consulting Company\\r\\nJOB TI...\n",
       "1       International Research & Exchanges Board (IREX...\n",
       "2       Caucasus Environmental NGO Network (CENN)\\r\\nJ...\n",
       "3       Manoff Group\\r\\nJOB TITLE:  BCC Specialist\\r\\n...\n",
       "4       Yerevan Brandy Company\\r\\nJOB TITLE:  Software...\n",
       "                              ...                        \n",
       "2995    British American Tobacco\\r\\nTITLE:  Merchandis...\n",
       "2996    ArmenTel CJSC\\r\\nTITLE:  Rating and Billing Co...\n",
       "2997    British American Tobacco (BAT)\\r\\nTITLE:  HoRe...\n",
       "2998    Partner Organization of Career Center\\r\\nTITLE...\n",
       "2999    Boomerang Software LLC\\r\\nTITLE:  Lawyer\\r\\nST...\n",
       "Name: jobpost, Length: 3000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"jobpost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|████████████████████▊                  | 1597/3000 [03:28<02:38,  8.83it/s]"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "helper_token = Tokenizer()\n",
    "df[\"vectors\"] = df[\"jobpost\"].progress_apply(helper_token.get_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a93ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7231350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2b25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=10, algorithm='auto')\n",
    "knn.fit(df['vectors'].to_numpy().tolist())\n",
    "\n",
    "def get_neighbors(vector):\n",
    "    return knn.kneighbors([vector], 10, return_distance=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0997168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_neighbours(df,number_of_neighbours):\n",
    "\n",
    "    def get_knn(df):\n",
    "        vector_arrays = df['vectors'].to_numpy().tolist()\n",
    "        return NearestNeighbors().fit(vector_arrays)        \n",
    "\n",
    "    def get_token():\n",
    "        helper_token = Tokenizer()\n",
    "        INPUT = input(\"Enter the Input Query \")\n",
    "        token_vector = helper_token.get_token(INPUT)\n",
    "        return token_vector\n",
    "\n",
    "    def flatten_neighbour_list(nb_indexes):\n",
    "        nb_list = nb_indexes.tolist()\n",
    "        return [item for sublist in nb_list for item in sublist]        \n",
    "\n",
    "    knn = get_knn(df)\n",
    "    vector = get_token()\n",
    "    nb_indexes = knn.kneighbors([vector],number_of_neighbours,return_distance=False)\n",
    "    nb_indexes = flatten_neighbour_list(nb_indexes)\n",
    "    \n",
    "    title_arrays = df['Title'].to_numpy().tolist()\n",
    "    post_arrays = df['jobpost'].to_numpy().tolist()\n",
    "    return_array = []\n",
    "    for num in nb_indexes:\n",
    "        return_array.append([title_arrays[num], post_arrays[num].replace('\\r', '').replace('\\n', '')])\n",
    "    \n",
    "    \n",
    "    return return_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b79b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_k_neighbours(df , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a8d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuralNine",
   "language": "python",
   "name": "neuralnine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
